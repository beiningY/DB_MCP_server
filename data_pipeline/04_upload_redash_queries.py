#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–è„šæœ¬ï¼šå°† Redash æŸ¥è¯¢ä¸Šä¼ åˆ° RAG ç³»ç»Ÿ
è¯»å– redash_queries.jsonï¼Œå°†æ¯ä¸ªæŸ¥è¯¢çš„ SQL å‘é€åˆ° RAG æ¥å£
"""

import json
import requests
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# é…ç½®
RAG_API_URL = "http://localhost:9621/documents/text"
REDASH_QUERIES_FILE = Path(__file__).parent.parent / "metadata" / "redash_queries.json"
MAX_WORKERS = 5  # å¹¶å‘è¯·æ±‚æ•°
RETRY_COUNT = 3  # å¤±è´¥é‡è¯•æ¬¡æ•°
RETRY_DELAY = 1  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰


def load_queries(file_path: Path) -> list:
    """åŠ è½½ Redash æŸ¥è¯¢æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data.get('queries', [])


def build_file_source(query: dict) -> str:
    """æ„å»º file_source å­—æ®µï¼šQuery{id}:{name}"""
    query_id = query.get('id', 'unknown')
    query_name = query.get('name', 'untitled')
    return f"Query{query_id}:{query_name}"


def upload_query(query: dict) -> dict:
    """
    ä¸Šä¼ å•ä¸ªæŸ¥è¯¢åˆ° RAG ç³»ç»Ÿ
    è¿”å›: {"success": bool, "file_source": str, "error": str or None}
    """
    file_source = build_file_source(query)
    sql_text = query.get('sql', '')
    
    # è·³è¿‡ç©º SQL
    if not sql_text.strip():
        return {
            "success": False,
            "file_source": file_source,
            "error": "Empty SQL"
        }
    
    payload = {
        "file_source": file_source,
        "text": sql_text
    }
    
    # å¸¦é‡è¯•çš„è¯·æ±‚
    for attempt in range(RETRY_COUNT):
        try:
            response = requests.post(
                RAG_API_URL,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            if response.status_code in (200, 201):
                return {
                    "success": True,
                    "file_source": file_source,
                    "error": None
                }
            else:
                error_msg = f"HTTP {response.status_code}: {response.text[:200]}"
                
        except requests.exceptions.RequestException as e:
            error_msg = str(e)
        
        # é‡è¯•å‰ç­‰å¾…
        if attempt < RETRY_COUNT - 1:
            time.sleep(RETRY_DELAY)
    
    return {
        "success": False,
        "file_source": file_source,
        "error": error_msg
    }


def main():
    """ä¸»å‡½æ•°ï¼šæ‰¹é‡ä¸Šä¼ æ‰€æœ‰æŸ¥è¯¢"""
    print(f"ğŸ“‚ è¯»å–æŸ¥è¯¢æ–‡ä»¶: {REDASH_QUERIES_FILE}")
    
    if not REDASH_QUERIES_FILE.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {REDASH_QUERIES_FILE}")
        return
    
    queries = load_queries(REDASH_QUERIES_FILE)
    total = len(queries)
    print(f"ğŸ“Š å…± {total} ä¸ªæŸ¥è¯¢å¾…å¤„ç†")
    
    # ç»Ÿè®¡ç»“æœ
    success_count = 0
    failed_count = 0
    failed_queries = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸Šä¼ 
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_query = {
            executor.submit(upload_query, query): query 
            for query in queries
        }
        
        # å¤„ç†ç»“æœå¹¶æ˜¾ç¤ºè¿›åº¦
        with tqdm(total=total, desc="ä¸Šä¼ è¿›åº¦", unit="query") as pbar:
            for future in as_completed(future_to_query):
                result = future.result()
                
                if result["success"]:
                    success_count += 1
                else:
                    failed_count += 1
                    failed_queries.append(result)
                
                pbar.update(1)
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 50)
    print(f"âœ… ä¸Šä¼ æˆåŠŸ: {success_count}")
    print(f"âŒ ä¸Šä¼ å¤±è´¥: {failed_count}")
    
    # æ‰“å°å¤±è´¥è¯¦æƒ…
    if failed_queries:
        print("\nğŸ“‹ å¤±è´¥è¯¦æƒ…:")
        for item in failed_queries[:20]:  # æœ€å¤šæ˜¾ç¤º 20 æ¡
            print(f"  - {item['file_source']}: {item['error']}")
        
        if len(failed_queries) > 20:
            print(f"  ... è¿˜æœ‰ {len(failed_queries) - 20} ä¸ªå¤±è´¥é¡¹")
        
        # ä¿å­˜å¤±è´¥è®°å½•åˆ°æ–‡ä»¶
        failed_log_path = Path(__file__).parent / "upload_failed.json"
        with open(failed_log_path, 'w', encoding='utf-8') as f:
            json.dump(failed_queries, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“ å¤±è´¥è®°å½•å·²ä¿å­˜åˆ°: {failed_log_path}")


if __name__ == "__main__":
    main()

