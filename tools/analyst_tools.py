"""
æ•°æ®åˆ†æå¸ˆ Agent å·¥å…·é›†
å®ç° 5 ç§æ ¸å¿ƒèƒ½åŠ›ï¼šå…ƒæ•°æ®æœç´¢ã€å†å²æŸ¥è¯¢ã€SQLæ‰§è¡Œã€æŸ¥è¯¢ä¼˜åŒ–ã€æ•°æ®åˆ†æ
"""

from typing import Any, Dict, List, Optional
import mcp.types as types
from .base import BaseTool

# å¯¼å…¥çŸ¥è¯†æ¨¡å—å’Œæ‰§è¡Œå™¨
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from knowledge import OnlineDictionaryModule, SingaBIMetadataModule, LightRAGClient
from executors import MySQLExecutor, RedashExecutor


class MetadataSearchTool(BaseTool):
    """å…ƒæ•°æ®æœç´¢å·¥å…· - æœç´¢è¡¨ç»“æ„ã€å­—æ®µå«ä¹‰ã€ä¸šåŠ¡åŸŸ"""
    
    def __init__(self, online_dict: OnlineDictionaryModule, metadata: SingaBIMetadataModule):
        self.online_dict = online_dict
        self.metadata = metadata
    
    @property
    def name(self) -> str:
        return "search_metadata"
    
    @property
    def description(self) -> str:
        return """æœç´¢æ•°æ®åº“å…ƒæ•°æ®ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
- è¡¨ç»“æ„å’Œå­—æ®µå®šä¹‰
- å­—æ®µçš„ä¸šåŠ¡å«ä¹‰å’Œæšä¸¾å€¼ï¼ˆæ¥è‡ªåœ¨çº¿å­—å…¸ï¼‰
- ä¸šåŠ¡åŸŸå’Œæ•°æ®ç²’åº¦
- è¡¨ä¹‹é—´çš„å…³è”å…³ç³»
- PII æ•æ„Ÿå­—æ®µæ ‡è¯†

ä½¿ç”¨åœºæ™¯ï¼š
- åœ¨ç”Ÿæˆ SQL å‰ï¼Œç¡®è®¤è¡¨åå’Œå­—æ®µåæ˜¯å¦æ­£ç¡®
- äº†è§£å­—æ®µçš„ä¸šåŠ¡å«ä¹‰å’Œå¯èƒ½çš„å–å€¼
- æŸ¥æ‰¾æŸä¸ªä¸šåŠ¡åŸŸä¸‹çš„æ‰€æœ‰è¡¨"""
    
    @property
    def input_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "æœç´¢å…³é”®è¯ï¼ˆè¡¨åã€å­—æ®µåæˆ–ä¸šåŠ¡åŸŸï¼‰"
                },
                "search_type": {
                    "type": "string",
                    "enum": ["auto", "table", "column", "domain"],
                    "description": "æœç´¢ç±»å‹ï¼Œé»˜è®¤ auto è‡ªåŠ¨åˆ¤æ–­",
                    "default": "auto"
                },
                "source": {
                    "type": "string",
                    "enum": ["both", "online_dict", "metadata"],
                    "description": "æ•°æ®æ¥æºï¼šboth(ä¸¤è€…), online_dict(åœ¨çº¿å­—å…¸), metadata(BIå…ƒæ•°æ®)",
                    "default": "both"
                }
            },
            "required": ["query"]
        }
    
    async def execute(self, arguments: dict[str, Any]) -> list[types.TextContent]:
        query = arguments.get("query", "")
        search_type = arguments.get("search_type", "auto")
        source = arguments.get("source", "both")
        
        results = []
        
        # åœ¨çº¿å­—å…¸æœç´¢
        if source in ["both", "online_dict"]:
            dict_result = await self.online_dict.search(query, search_type=search_type)
            formatted = self.online_dict.format_result(dict_result)
            results.append(f"## åœ¨çº¿å­—å…¸æœç´¢ç»“æœ\n\n{formatted}")
        
        # å…ƒæ•°æ®æœç´¢
        if source in ["both", "metadata"]:
            if search_type == "domain":
                meta_result = await self.metadata.search_by_domain(query)
            else:
                meta_result = await self.metadata.search(query, search_type=search_type)
            formatted = self.metadata.format_result(meta_result)
            results.append(f"## BI å…ƒæ•°æ®æœç´¢ç»“æœ\n\n{formatted}")
        
        output = "\n\n---\n\n".join(results)
        return [types.TextContent(type="text", text=output)]


class HistoricalQuerySearchTool(BaseTool):
    """å†å²æŸ¥è¯¢æœç´¢å·¥å…· - é€šè¿‡ LightRAG æœç´¢ç›¸ä¼¼çš„å†å² SQL"""
    
    def __init__(self, lightrag_client: LightRAGClient):
        self.lightrag = lightrag_client
    
    @property
    def name(self) -> str:
        return "search_historical_queries"
    
    @property
    def description(self) -> str:
        return """æœç´¢ç›¸ä¼¼çš„å†å² SQL æŸ¥è¯¢ä½œä¸ºå‚è€ƒã€‚

LightRAG ä¼šæ ¹æ®è¯­ä¹‰ç›¸ä¼¼åº¦æ‰¾åˆ°å†å²ä¸Šç±»ä¼¼çš„æŸ¥è¯¢ï¼ŒåŒ…æ‹¬ï¼š
- æŸ¥è¯¢åç§°å’Œæè¿°
- å®Œæ•´çš„ SQL è¯­å¥
- ä½¿ç”¨çš„è¡¨å’Œå­—æ®µ
- ç›¸å…³çš„ Dashboard

ä½¿ç”¨åœºæ™¯ï¼š
- å‚è€ƒå†å²æŸ¥è¯¢çš„å†™æ³•å’Œæ¨¡å¼
- äº†è§£æŸç±»ä¸šåŠ¡æŒ‡æ ‡çš„è®¡ç®—æ–¹æ³•
- å¤ç”¨å·²æœ‰çš„æŸ¥è¯¢é€»è¾‘"""
    
    @property
    def input_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "intent": {
                    "type": "string",
                    "description": "ç”¨æˆ·æ„å›¾çš„è‡ªç„¶è¯­è¨€æè¿°ï¼ˆä¾‹å¦‚ï¼šæŸ¥è¯¢æ˜¨å¤©çš„æ”¾æ¬¾é‡‘é¢ï¼‰"
                },
                "top_k": {
                    "type": "integer",
                    "description": "è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ 3",
                    "default": 3
                },
                "mode": {
                    "type": "string",
                    "enum": ["naive", "local", "global", "hybrid"],
                    "description": "æ£€ç´¢æ¨¡å¼ï¼Œæ¨èä½¿ç”¨ hybrid",
                    "default": "hybrid"
                }
            },
            "required": ["intent"]
        }
    
    async def execute(self, arguments: dict[str, Any]) -> list[types.TextContent]:
        intent = arguments.get("intent", "")
        top_k = arguments.get("top_k", 3)
        mode = arguments.get("mode", "hybrid")
        
        # æœç´¢å†å²æŸ¥è¯¢
        queries = await self.lightrag.search_historical_queries(intent, top_k=top_k)
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted = self.lightrag.format_historical_queries(queries)
        
        return [types.TextContent(type="text", text=formatted)]


class SQLExecutorTool(BaseTool):
    """SQL æ‰§è¡Œå·¥å…· - æ”¯æŒ MySQL ç›´è¿å’Œ Redash API ä¸¤ç§æ–¹å¼"""
    
    def __init__(self, mysql_executor: MySQLExecutor, redash_executor: RedashExecutor):
        self.mysql = mysql_executor
        self.redash = redash_executor
    
    @property
    def name(self) -> str:
        return "execute_sql"
    
    @property
    def description(self) -> str:
        return """æ‰§è¡Œ SQL æŸ¥è¯¢ï¼Œæ”¯æŒä¸¤ç§æ‰§è¡Œæ–¹å¼ï¼š

1. MySQL ç›´è¿ï¼ˆé»˜è®¤ï¼‰ï¼šå¿«é€Ÿï¼Œé€‚åˆç®€å•æŸ¥è¯¢
2. Redash APIï¼šæ”¯æŒæƒé™ç®¡ç†å’Œå®¡è®¡ï¼Œé€‚åˆéœ€è¦è®°å½•çš„æŸ¥è¯¢

å®‰å…¨é™åˆ¶ï¼š
- åªå…è®¸ SELECT æŸ¥è¯¢
- é»˜è®¤æœ€å¤šè¿”å› 10000 è¡Œ
- æŸ¥è¯¢è¶…æ—¶æ—¶é—´ 30 ç§’

ä½¿ç”¨æç¤ºï¼š
- æ‰§è¡Œå‰è¯·å…ˆä½¿ç”¨ search_metadata ç¡®è®¤è¡¨åå’Œå­—æ®µå
- å¯¹äºå¤æ‚æŸ¥è¯¢ï¼Œå»ºè®®å…ˆä½¿ç”¨ search_historical_queries å‚è€ƒå†å²å†™æ³•"""
    
    @property
    def input_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "sql": {
                    "type": "string",
                    "description": "è¦æ‰§è¡Œçš„ SQL æŸ¥è¯¢è¯­å¥ï¼ˆåªå…è®¸ SELECTï¼‰"
                },
                "use_redash": {
                    "type": "boolean",
                    "description": "æ˜¯å¦ä½¿ç”¨ Redash API æ‰§è¡Œï¼ˆé»˜è®¤ falseï¼Œä½¿ç”¨ MySQL ç›´è¿ï¼‰",
                    "default": False
                },
                "timeout": {
                    "type": "integer",
                    "description": "æŸ¥è¯¢è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 30",
                    "default": 30
                },
                "limit": {
                    "type": "integer",
                    "description": "æœ€å¤§è¿”å›è¡Œæ•°ï¼Œé»˜è®¤ 10000",
                    "default": 10000
                }
            },
            "required": ["sql"]
        }
    
    async def execute(self, arguments: dict[str, Any]) -> list[types.TextContent]:
        sql = arguments.get("sql", "")
        use_redash = arguments.get("use_redash", False)
        timeout = arguments.get("timeout", 30)
        limit = arguments.get("limit", 10000)
        
        # é€‰æ‹©æ‰§è¡Œå™¨
        executor = self.redash if use_redash else self.mysql
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = await executor.execute(sql, timeout=timeout, limit=limit)
        
        # æ ¼å¼åŒ–ç»“æœ
        if result.success:
            output = result.format_table(max_rows=20)
            
            # æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
            output += f"\n\n**æ‰§è¡Œä¿¡æ¯**:\n"
            output += f"- æ‰§è¡Œå™¨: {executor.name}\n"
            output += f"- è€—æ—¶: {result.execution_time:.2f}ç§’\n"
            output += f"- æ€»è¡Œæ•°: {result.row_count}\n"
            
            if result.metadata:
                if result.metadata.get('limited'):
                    output += f"- âš ï¸ ç»“æœå·²è¢«é™åˆ¶ä¸º {limit} è¡Œ\n"
        else:
            output = result.format_table()
        
        return [types.TextContent(type="text", text=output)]


class QueryOptimizationTool(BaseTool):
    """æŸ¥è¯¢ä¼˜åŒ–å·¥å…· - åˆ†æ SQL å¹¶æä¾›ä¼˜åŒ–å»ºè®®"""
    
    @property
    def name(self) -> str:
        return "optimize_query"
    
    @property
    def description(self) -> str:
        return """åˆ†æ SQL æŸ¥è¯¢å¹¶æä¾›ä¼˜åŒ–å»ºè®®ã€‚

æ£€æŸ¥é¡¹åŒ…æ‹¬ï¼š
- æ˜¯å¦ä½¿ç”¨äº†åˆé€‚çš„ç´¢å¼•
- JOIN çš„é¡ºåºå’Œç±»å‹
- WHERE æ¡ä»¶çš„ä¼˜åŒ–
- SELECT å­—æ®µçš„é€‰æ‹©
- æ˜¯å¦å­˜åœ¨å­æŸ¥è¯¢å¯ä»¥ä¼˜åŒ–
- æ˜¯å¦éœ€è¦æ·»åŠ  LIMIT

ä½¿ç”¨åœºæ™¯ï¼š
- æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¿‡é•¿
- æƒ³è¦æé«˜æŸ¥è¯¢æ€§èƒ½
- äº†è§£æŸ¥è¯¢çš„æ½œåœ¨é—®é¢˜"""
    
    @property
    def input_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "sql": {
                    "type": "string",
                    "description": "è¦ä¼˜åŒ–çš„ SQL è¯­å¥"
                },
                "explain": {
                    "type": "boolean",
                    "description": "æ˜¯å¦æ‰§è¡Œ EXPLAIN åˆ†æï¼ˆéœ€è¦æ•°æ®åº“è¿æ¥ï¼‰",
                    "default": False
                }
            },
            "required": ["sql"]
        }
    
    async def execute(self, arguments: dict[str, Any]) -> list[types.TextContent]:
        sql = arguments.get("sql", "")
        run_explain = arguments.get("explain", False)
        
        suggestions = []
        
        # åŸºç¡€åˆ†æ
        sql_upper = sql.upper()
        
        # 1. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† SELECT *
        if "SELECT *" in sql_upper or "SELECT\n*" in sql_upper:
            suggestions.append({
                "type": "performance",
                "issue": "ä½¿ç”¨äº† SELECT *",
                "suggestion": "åªé€‰æ‹©éœ€è¦çš„å­—æ®µï¼Œé¿å…ä¼ è¾“ä¸å¿…è¦çš„æ•°æ®",
                "severity": "medium"
            })
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰ LIMIT
        if "LIMIT" not in sql_upper:
            suggestions.append({
                "type": "safety",
                "issue": "æ²¡æœ‰ LIMIT å­å¥",
                "suggestion": "æ·»åŠ  LIMIT å­å¥ä»¥é¿å…è¿”å›å¤§é‡æ•°æ®",
                "severity": "high"
            })
        
        # 3. æ£€æŸ¥ JOIN ç±»å‹
        if "JOIN" in sql_upper:
            if "LEFT JOIN" in sql_upper or "RIGHT JOIN" in sql_upper:
                suggestions.append({
                    "type": "performance",
                    "issue": "ä½¿ç”¨äº†å¤–è¿æ¥",
                    "suggestion": "å¦‚æœä¸éœ€è¦NULLå€¼ï¼Œè€ƒè™‘ä½¿ç”¨ INNER JOIN æé«˜æ€§èƒ½",
                    "severity": "low"
                })
        
        # 4. æ£€æŸ¥å­æŸ¥è¯¢
        if sql.count("SELECT") > 1:
            suggestions.append({
                "type": "performance",
                "issue": "åŒ…å«å­æŸ¥è¯¢",
                "suggestion": "è€ƒè™‘ä½¿ç”¨ JOIN æˆ– CTE (WITH) æ›¿ä»£å­æŸ¥è¯¢",
                "severity": "medium"
            })
        
        # 5. æ£€æŸ¥ WHERE æ¡ä»¶
        if " WHERE " in sql_upper:
            where_clause = sql_upper.split(" WHERE ")[1].split(" ORDER ")[0].split(" GROUP ")[0]
            if " OR " in where_clause:
                suggestions.append({
                    "type": "index",
                    "issue": "WHERE æ¡ä»¶ä¸­ä½¿ç”¨äº† OR",
                    "suggestion": "OR å¯èƒ½å¯¼è‡´ç´¢å¼•å¤±æ•ˆï¼Œè€ƒè™‘ä½¿ç”¨ UNION æˆ– IN",
                    "severity": "medium"
                })
            
            # æ£€æŸ¥å‡½æ•°åœ¨å­—æ®µä¸Š
            if "(" in where_clause and any(func in where_clause for func in ["DATE(", "YEAR(", "MONTH("]):
                suggestions.append({
                    "type": "index",
                    "issue": "WHERE æ¡ä»¶ä¸­å¯¹å­—æ®µä½¿ç”¨äº†å‡½æ•°",
                    "suggestion": "å¯¹å­—æ®µä½¿ç”¨å‡½æ•°ä¼šå¯¼è‡´ç´¢å¼•å¤±æ•ˆï¼Œè€ƒè™‘æ”¹å†™æ¡ä»¶",
                    "severity": "high"
                })
        
        # 6. æ£€æŸ¥ ORDER BY
        if " ORDER BY " in sql_upper:
            order_clause = sql_upper.split(" ORDER BY ")[1]
            if " LIMIT " not in order_clause:
                suggestions.append({
                    "type": "performance",
                    "issue": "ORDER BY ä½†æ²¡æœ‰ LIMIT",
                    "suggestion": "å¦‚æœåªéœ€è¦éƒ¨åˆ†æ’åºç»“æœï¼Œæ·»åŠ  LIMIT å¯ä»¥æé«˜æ€§èƒ½",
                    "severity": "low"
                })
        
        # 7. æ£€æŸ¥ DISTINCT
        if " DISTINCT " in sql_upper:
            suggestions.append({
                "type": "performance",
                "issue": "ä½¿ç”¨äº† DISTINCT",
                "suggestion": "DISTINCT å¯èƒ½å½±å“æ€§èƒ½ï¼Œç¡®è®¤æ˜¯å¦çœŸçš„éœ€è¦å»é‡",
                "severity": "medium"
            })
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = [f"## SQL ä¼˜åŒ–åˆ†æ\n\n**åŸå§‹ SQL**:\n```sql\n{sql}\n```\n"]
        
        if suggestions:
            output.append(f"\n**å‘ç° {len(suggestions)} ä¸ªä¼˜åŒ–å»ºè®®**:\n")
            for i, sugg in enumerate(suggestions, 1):
                severity_emoji = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}[sugg['severity']]
                output.append(f"{i}. {severity_emoji} **{sugg['issue']}** ({sugg['type']})")
                output.append(f"   {sugg['suggestion']}\n")
        else:
            output.append("\nâœ“ æœªå‘ç°æ˜æ˜¾çš„ä¼˜åŒ–é—®é¢˜")
        
        # TODO: å¦‚æœ run_explain=Trueï¼Œæ‰§è¡Œ EXPLAIN å¹¶åˆ†æç»“æœ
        if run_explain:
            output.append("\n*EXPLAIN åˆ†æåŠŸèƒ½æš‚æœªå®ç°*")
        
        return [types.TextContent(type="text", text="\n".join(output))]


class DataAnalysisTool(BaseTool):
    """æ•°æ®åˆ†æå·¥å…· - å¯¹æŸ¥è¯¢ç»“æœç”Ÿæˆç»Ÿè®¡åˆ†æå’Œæ´å¯Ÿ"""
    
    @property
    def name(self) -> str:
        return "analyze_data"
    
    @property
    def description(self) -> str:
        return """å¯¹æŸ¥è¯¢ç»“æœè¿›è¡Œæ•°æ®åˆ†æï¼Œç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å’Œæ´å¯Ÿã€‚

åˆ†æå†…å®¹åŒ…æ‹¬ï¼š
- æ•°å€¼å­—æ®µçš„ç»Ÿè®¡ï¼ˆæœ€å¤§å€¼ã€æœ€å°å€¼ã€å¹³å‡å€¼ã€ä¸­ä½æ•°ï¼‰
- åˆ†ç±»å­—æ®µçš„åˆ†å¸ƒ
- è¶‹åŠ¿åˆ†æï¼ˆå¦‚æœæœ‰æ—¶é—´å­—æ®µï¼‰
- å¼‚å¸¸å€¼æ£€æµ‹
- å¯è§†åŒ–å»ºè®®

ä½¿ç”¨åœºæ™¯ï¼š
- å¿«é€Ÿäº†è§£æ•°æ®çš„åŸºæœ¬ç‰¹å¾
- å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼å’Œå¼‚å¸¸
- ä¸ºè¿›ä¸€æ­¥åˆ†ææä¾›æ–¹å‘"""
    
    @property
    def input_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "data": {
                    "type": "string",
                    "description": "è¦åˆ†æçš„æ•°æ®ï¼ˆJSON æ ¼å¼æˆ–æ¥è‡ª execute_sql çš„ç»“æœï¼‰"
                },
                "analysis_type": {
                    "type": "string",
                    "enum": ["summary", "distribution", "trend", "all"],
                    "description": "åˆ†æç±»å‹ï¼Œé»˜è®¤ allï¼ˆå…¨éƒ¨ï¼‰",
                    "default": "all"
                }
            },
            "required": ["data"]
        }
    
    async def execute(self, arguments: dict[str, Any]) -> list[types.TextContent]:
        data_str = arguments.get("data", "")
        analysis_type = arguments.get("analysis_type", "all")
        
        # ç®€å•çš„æ•°æ®åˆ†æç¤ºä¾‹ï¼ˆå®é™…åº”è¯¥æ›´å¤æ‚ï¼‰
        output = [
            "## æ•°æ®åˆ†æç»“æœ\n",
            "*æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªåŸºç¡€çš„æ•°æ®åˆ†æå·¥å…·ï¼Œæ›´å¤æ‚çš„åˆ†æå»ºè®®ä½¿ç”¨ä¸“ä¸šå·¥å…·*\n",
            f"\n**åˆ†æç±»å‹**: {analysis_type}\n",
            "\n**å»ºè®®**:\n",
            "- ä½¿ç”¨ pandas è¿›è¡Œæ›´æ·±å…¥çš„ç»Ÿè®¡åˆ†æ\n",
            "- ä½¿ç”¨ matplotlib/seaborn è¿›è¡Œæ•°æ®å¯è§†åŒ–\n",
            "- ä½¿ç”¨ numpy è¿›è¡Œæ•°å€¼è®¡ç®—\n"
        ]
        
        return [types.TextContent(type="text", text="\n".join(output))]


# å¯¼å‡ºæ‰€æœ‰å·¥å…·
__all__ = [
    'MetadataSearchTool',
    'HistoricalQuerySearchTool',
    'SQLExecutorTool',
    'QueryOptimizationTool',
    'DataAnalysisTool',
]
